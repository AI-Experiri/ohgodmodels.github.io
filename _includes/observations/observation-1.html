<!-- Observation 1: The Industry Is Closed -->
{% include observations/observation-detail.html
    id="observation-1"
    number="01"
    title="The Industry Is Closed"
    bg="bg-terminal-bg"
    problem="A handful of companies control the compute, models, and data that power AI, and they tell us nothing about how it works. Training frontier models costs hundreds of millions. GPU computing flows through two or three companies. And what do we get in return? Stanford's Foundation Model Transparency Index (2025) scored major AI companies at just 41/100, down 17 points from 2024. OpenAI dropped 14 points. Meta dropped 29. Only 30% of companies even responded to transparency requests. This isn't conspiracy; it's economics. Concentration enables secrecy. Secrecy protects concentration."
    quote="Transparency is a vital precondition for public accountability, scientific innovation, and effective governance."
    quote_source="<a href='https://arxiv.org/abs/2310.12941' target='_blank' class='text-terminal-green hover:underline'>Stanford Foundation Model Transparency Index</a>"
    why_matters="When only a few can build, only a few decide what gets built. When they won't show their work, we can't verify their claims. Research narrows. Innovation follows money. Science requires verification. Democracy requires transparency. We're building critical infrastructure on foundations we cannot examine, and 'trust us' isn't good enough."
    ohgod_solution="OHGOD!! What if powerful AI can be trained on a consumer GPU in 24 hours? The compute moat disappears. What if every architecture choice, training dataset, and failure mode is documented? No black boxes. No 'trust us.' You train it yourself, so you know what's inside. The industry scores 41/100 on transparency. We aim for 100."
%}
